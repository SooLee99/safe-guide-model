{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "478b773a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFRecord 파일이 손상되었습니다. 파일을 다시 생성해주세요.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import dataset_util, config_util\n",
    "from object_detection.builders import model_builder\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 경로 설정\n",
    "root_dir = 'D:/베리어프리존(장애물 없는 생활공간) 주행영상'\n",
    "training_tfrecord_file = os.path.join(root_dir, 'Training', 'jpg.tfrecord')\n",
    "validation_tfrecord_file = os.path.join(root_dir, 'Validation', 'jpg.tfrecord')\n",
    "pipeline_config_path = 'C:/ssd_mobilenet_v2_320x320_coco17_tpu-8/ssd_mobilenet_v2_320x320_coco17_tpu-8/pipeline.config'\n",
    "model_dir = 'C:/AI_hub/model'\n",
    "\n",
    "# 데이터셋 로드 함수\n",
    "def load_dataset(tfrecord_file, batch_size):\n",
    "    feature_description = {\n",
    "        'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/source_id': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/format': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/class/text': tf.io.VarLenFeature(tf.string),\n",
    "        'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
    "    }\n",
    "\n",
    "    def parse_example(example_proto):\n",
    "        try:\n",
    "            return tf.io.parse_single_example(example_proto, feature_description)\n",
    "        except tf.errors.DataLossError:\n",
    "            raise ValueError(\"Corrupted record encountered. Please remove the corrupted record and try again.\")\n",
    "\n",
    "    def decode_image(parsed_example):\n",
    "        image = tf.image.decode_image(parsed_example['image/encoded'], channels=3)\n",
    "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "        return image\n",
    "\n",
    "    def process_data(parsed_example):\n",
    "        image = decode_image(parsed_example)\n",
    "        labels = parsed_example['image/object/class/label']\n",
    "        return image, labels\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_example, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.filter(lambda x: x is not None)\n",
    "    dataset = dataset.map(process_data, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(1000)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    dataset_size = tf.data.experimental.cardinality(dataset).numpy()\n",
    "\n",
    "    return dataset, dataset_size\n",
    "\n",
    "# 모델 구성 로드\n",
    "pipeline_config = config_util.get_configs_from_pipeline_file(pipeline_config_path)\n",
    "model_config = pipeline_config['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=True)\n",
    "\n",
    "# 모델 빌드\n",
    "@tf.function\n",
    "def build_model(input):\n",
    "    detection_model(input)\n",
    "\n",
    "# 빈 입력으로 모델 빌드\n",
    "dummy_input = tf.ones((1, 320, 320, 3))\n",
    "build_model(dummy_input)\n",
    "\n",
    "# 옵티마이저 설정\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# 체크포인트 설정\n",
    "checkpoint_dir = 'C:/AI_hub/checkpoints'\n",
    "checkpoint = tf.train.Checkpoint(model=detection_model, optimizer=optimizer)\n",
    "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "# 최신 체크포인트를 로드하고, 상태를 복구\n",
    "if latest_checkpoint:\n",
    "    checkpoint.restore(latest_checkpoint)\n",
    "    print(\"Loaded checkpoint:\", latest_checkpoint)\n",
    "\n",
    "# 손상된 파일 확인 함수\n",
    "def is_file_corrupted(tfrecord_file):\n",
    "    try:\n",
    "        with open(tfrecord_file, 'rb') as file:\n",
    "            file.read()\n",
    "        return False\n",
    "    except:\n",
    "        return True\n",
    "\n",
    "# 손상된 파일이 있다면 경고 메시지 출력\n",
    "if is_file_corrupted(training_tfrecord_file):\n",
    "    print(\"TFRecord 파일이 손상되었습니다. 파일을 다시 생성해주세요.\")\n",
    "else:\n",
    "    # 배치 사이즈 설정\n",
    "    batch_size = 32\n",
    "\n",
    "    # 데이터셋 로드\n",
    "    training_dataset, training_size = load_dataset(training_tfrecord_file, batch_size)\n",
    "    validation_dataset, validation_size = load_dataset(validation_tfrecord_file, batch_size)\n",
    "\n",
    "    # 훈련 시작\n",
    "    for epoch in range(10):\n",
    "        for inputs, labels in tqdm(training_dataset):\n",
    "            with tf.GradientTape() as tape:\n",
    "                predictions = detection_model(inputs)\n",
    "                loss = compute_loss(labels, predictions)\n",
    "            gradients = tape.gradient(loss, detection_model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, detection_model.trainable_variables))\n",
    "        print(\"Epoch\", epoch, \"finished\")\n",
    "\n",
    "        # 검증 시작\n",
    "        for inputs, labels in tqdm(validation_dataset):\n",
    "            predictions = detection_model(inputs)\n",
    "            loss = compute_loss(labels, predictions)\n",
    "        print(\"Validation loss:\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ba2745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805c141f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 파일 시스템 초기화\n",
      "손실 함수 정의\n",
      "pipeline.config 파일 열기\n",
      "input_path 수정\n",
      "수정된 내용으로 pipeline.config 파일 저장\n",
      "모델 구성 로드\n",
      "빈 입력으로 모델 빌드\n",
      "모델 빌드\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 빌드\n",
      "옵티마이저 설정\n",
      "체크포인트 설정\n",
      "데이터셋 로드\n",
      "데이터셋 로드 함수\n",
      "is_file_corrupted 함수\n",
      "dataset\n",
      "parse_example 함수\n",
      "process_data 함수\n",
      "decode_image 함수\n",
      "데이터셋 로드 함수\n",
      "is_file_corrupted 함수\n",
      "dataset\n",
      "parse_example 함수\n",
      "process_data 함수\n",
      "decode_image 함수\n",
      "훈련 및 검증 시작\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import dataset_util, config_util\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.core import losses\n",
    "import os\n",
    "import s3fs\n",
    "import time\n",
    "\n",
    "num_classes = 98\n",
    "\n",
    "# AWS S3 액세스 키 및 시크릿 액세스 키 설정\n",
    "access_key = 'access_key'\n",
    "secret_key = 'secret_key'\n",
    "\n",
    "# S3 파일 시스템 초기화\n",
    "print(\"S3 파일 시스템 초기화\")\n",
    "fs = s3fs.S3FileSystem(key=access_key, secret=secret_key)\n",
    "\n",
    "# 버킷 설정\n",
    "source_bucket_name = 'tfrecord-bucket02'\n",
    "destination_bucket_name = 'module-bucket01'\n",
    "\n",
    "# 손실 함수 정의\n",
    "print(\"손실 함수 정의\")\n",
    "binary_crossentropy = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "def compute_loss(labels, predictions):\n",
    "    print(\"compute_loss\")\n",
    "    localization_loss = binary_crossentropy(labels['groundtruth_boxes'], predictions['predicted_boxes'])\n",
    "    classification_loss = binary_crossentropy(labels['groundtruth_classes'], predictions['predicted_classes'])\n",
    "    return {'localization_loss': localization_loss, 'classification_loss': classification_loss}\n",
    "\n",
    "# 경로 설정\n",
    "training_tfrecord_file = 's3://{}/training.tfrecord'.format(source_bucket_name)\n",
    "validation_tfrecord_file = 's3://{}/validation.tfrecord'.format(source_bucket_name)\n",
    "pipeline_config_path = 'C:/ssd_mobilenet_v2_320x320_coco17_tpu-8/ssd_mobilenet_v2_320x320_coco17_tpu-8/pipeline.config'\n",
    "model_dir = 'C:/AI_hub/model'\n",
    "\n",
    "# pipeline.config 파일 열기\n",
    "with open(pipeline_config_path, 'r') as f:\n",
    "    print(\"pipeline.config 파일 열기\")\n",
    "    config_data = f.read()\n",
    "\n",
    "# input_path 수정\n",
    "print(\"input_path 수정\")\n",
    "config_data = config_data.replace('input_path: \"s3://tfrecord-bucket02/validation.tfrecord\"\"', 'input_path: \"{}\"'.format(validation_tfrecord_file))\n",
    "\n",
    "# 수정된 내용으로 pipeline.config 파일 저장\n",
    "with open(pipeline_config_path, 'w', newline='\\n') as f:\n",
    "    print(\"수정된 내용으로 pipeline.config 파일 저장\")\n",
    "    f.write(config_data)\n",
    "\n",
    "# 데이터셋 로드 함수\n",
    "def load_dataset(tfrecord_file, batch_size):\n",
    "    print(\"데이터셋 로드 함수\")\n",
    "    feature_description = {\n",
    "        'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/source_id': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/format': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/class/text': tf.io.VarLenFeature(tf.string),\n",
    "        'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
    "    }\n",
    "\n",
    "    def parse_example(example_proto):\n",
    "        print(\"parse_example 함수\")\n",
    "        try:\n",
    "            return tf.io.parse_single_example(example_proto, feature_description)\n",
    "        except tf.errors.DataLossError:\n",
    "            raise ValueError(\"Corrupted record encountered. Please remove the corrupted record and try again.\")\n",
    "\n",
    "    def decode_image(parsed_example):\n",
    "        print(\"decode_image 함수\")\n",
    "        image = tf.image.decode_image(parsed_example['image/encoded'], channels=3)\n",
    "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "        return image\n",
    "\n",
    "    def process_data(parsed_example):\n",
    "        print(\"process_data 함수\")\n",
    "        image = decode_image(parsed_example)\n",
    "        boxes = tf.stack([\n",
    "            tf.sparse.to_dense(parsed_example['image/object/bbox/xmin']),\n",
    "            tf.sparse.to_dense(parsed_example['image/object/bbox/ymin']),\n",
    "            tf.sparse.to_dense(parsed_example['image/object/bbox/xmax']),\n",
    "            tf.sparse.to_dense(parsed_example['image/object/bbox/ymax'])\n",
    "        ], axis=-1)\n",
    "\n",
    "        classes = tf.sparse.to_dense(parsed_example['image/object/class/label'])\n",
    "        classes = tf.one_hot(classes, depth=num_classes)\n",
    "        labels = {'groundtruth_boxes': boxes, 'groundtruth_classes': classes}\n",
    "        return image, labels\n",
    "\n",
    "    def is_file_corrupted(file_path):\n",
    "        print(\"is_file_corrupted 함수\")\n",
    "        try:\n",
    "            with fs.open(file_path, 'rb') as file:\n",
    "                file.read()\n",
    "            return False\n",
    "        except:\n",
    "            return True\n",
    "\n",
    "    if is_file_corrupted(tfrecord_file):\n",
    "        raise ValueError(\"TFRecord 파일이 손상되었습니다. 파일을 다시 생성해주세요.\")\n",
    "        \n",
    "    print(\"dataset\")\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file, compression_type='GZIP')\n",
    "    dataset = dataset.map(parse_example, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.filter(lambda x: x is not None)\n",
    "    dataset = dataset.map(process_data, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(1000)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    dataset_size = tf.data.experimental.cardinality(dataset).numpy()\n",
    "\n",
    "    return dataset, dataset_size\n",
    "\n",
    "# 모델 구성 로드\n",
    "print(\"모델 구성 로드\")\n",
    "pipeline_config = config_util.get_configs_from_pipeline_file(pipeline_config_path)\n",
    "model_config = pipeline_config['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=True)\n",
    "\n",
    "# 모델 빌드\n",
    "@tf.function\n",
    "def build_model(input):\n",
    "    print(\"모델 빌드\")\n",
    "    detection_model(input)\n",
    "\n",
    "# 빈 입력으로 모델 빌드\n",
    "print(\"빈 입력으로 모델 빌드\")\n",
    "dummy_input = tf.ones((1, 320, 320, 3))\n",
    "build_model(dummy_input)\n",
    "\n",
    "# 옵티마이저 설정\n",
    "print(\"옵티마이저 설정\")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# 체크포인트 설정\n",
    "print(\"체크포인트 설정\")\n",
    "checkpoint_dir = 'C:/AI_hub/checkpoints'\n",
    "checkpoint = tf.train.Checkpoint(model=detection_model, optimizer=optimizer)\n",
    "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "\n",
    "# 최신 체크포인트를 로드하고, 상태를 복구\n",
    "if latest_checkpoint:\n",
    "    print(\"최신 체크포인트를 로드하고, 상태를 복구\")\n",
    "    checkpoint.restore(latest_checkpoint)\n",
    "    print(\"Loaded checkpoint:\", latest_checkpoint)\n",
    "\n",
    "# 훈련 및 검증 시작\n",
    "def train_and_evaluate(training_dataset, validation_dataset, num_epochs):\n",
    "    print(\"훈련 및 검증 시작\")\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"1\")\n",
    "        start_time = time.time()  # 학습 시작 시간 기록\n",
    "        for inputs, labels in training_dataset:\n",
    "            with tf.GradientTape() as tape:\n",
    "                print(\"2\")\n",
    "                preprocessed_images = tf.image.resize(inputs, (320, 320))\n",
    "                print(\"3\")\n",
    "                prediction_dict = detection_model.predict(preprocessed_images)\n",
    "                print(\"4\")\n",
    "                losses_dict = compute_loss(labels, prediction_dict)\n",
    "                print(\"5\")\n",
    "                total_loss = losses_dict['localization_loss'] + losses_dict['classification_loss']\n",
    "                print(\"6\")\n",
    "            print(\"7\")\n",
    "            gradients = tape.gradient(total_loss, detection_model.trainable_variables)\n",
    "            print(\"8\")\n",
    "            optimizer.apply_gradients(zip(gradients, detection_model.trainable_variables))\n",
    "        print(\"Epoch\", epoch, \"finished\")\n",
    "        end_time = time.time()  # 학습 종료 시간 기록\n",
    "        elapsed_time = end_time - start_time  # 학습 시간 계산\n",
    "        print(\"Elapsed time: {:.2f} seconds\".format(elapsed_time))\n",
    "\n",
    "        validation_loss = 0.0\n",
    "        num_batches = 0\n",
    "        for inputs, labels in validation_dataset:\n",
    "            preprocessed_images = tf.image.resize(inputs, (320, 320))\n",
    "            prediction_dict = detection_model.predict(preprocessed_images)\n",
    "            losses_dict = compute_loss(labels, prediction_dict)\n",
    "            validation_loss += losses_dict['localization_loss'] + losses_dict['classification_loss']\n",
    "            num_batches += 1\n",
    "        validation_loss /= num_batches\n",
    "        print(\"Validation loss:\", validation_loss)\n",
    "\n",
    "# 배치 사이즈 설정\n",
    "batch_size = 32\n",
    "\n",
    "# 데이터셋 로드\n",
    "try:\n",
    "    print(\"데이터셋 로드\")\n",
    "    training_dataset, training_size = load_dataset(training_tfrecord_file, batch_size)\n",
    "    validation_dataset, validation_size = load_dataset(validation_tfrecord_file, batch_size)\n",
    "\n",
    "    # 훈련 및 검증 시작\n",
    "    train_and_evaluate(training_dataset, validation_dataset, num_epochs=10)\n",
    "except Exception as e:\n",
    "    print(\"Failed to load dataset:\", str(e))\n",
    "\n",
    "# 학습이 완료된 모델을 저장\n",
    "model_dir = 'C:/AI_hub/model'\n",
    "checkpoint.save(file_prefix=os.path.join(model_dir, 'ckpt'))\n",
    "\n",
    "# 모델을 S3에 업로드\n",
    "model_files = [\n",
    "    os.path.join(model_dir, 'ckpt.data-00000-of-00001'),\n",
    "    os.path.join(model_dir, 'ckpt.index'),\n",
    "    os.path.join(model_dir, 'ckpt.meta')\n",
    "]\n",
    "\n",
    "for model_file in model_files:\n",
    "    destination_path = 's3://{}/{}'.format(destination_bucket_name, os.path.basename(model_file))\n",
    "    try:\n",
    "        fs.put(model_file, destination_path)\n",
    "        print(\"Uploaded model file:\", destination_path)\n",
    "    except Exception as e:\n",
    "        print(\"Failed to upload model file:\", str(e))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
